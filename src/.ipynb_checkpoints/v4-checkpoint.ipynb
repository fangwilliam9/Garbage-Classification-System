{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfcc81f-946b-4c0e-812d-875983721f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2527 files belonging to 6 classes.\n",
      "Using 2022 files for training.\n",
      "Found 2527 files belonging to 6 classes.\n",
      "Using 505 files for validation.\n",
      "类别索引映射: ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
      "Class plastic: 394 samples\n",
      "Class cardboard: 320 samples\n",
      "Class metal: 332 samples\n",
      "Class paper: 470 samples\n",
      "Class glass: 398 samples\n",
      "Class trash: 108 samples\n",
      "Epoch 1/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 602ms/step - accuracy: 0.3605 - loss: 2.0489 - val_accuracy: 0.7390 - val_loss: 1.0268\n",
      "Epoch 2/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 585ms/step - accuracy: 0.6529 - loss: 1.1488 - val_accuracy: 0.8032 - val_loss: 0.7986\n",
      "Epoch 3/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 587ms/step - accuracy: 0.7254 - loss: 0.9917 - val_accuracy: 0.8153 - val_loss: 0.7485\n",
      "Epoch 4/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 586ms/step - accuracy: 0.7265 - loss: 0.9768 - val_accuracy: 0.8474 - val_loss: 0.7135\n",
      "Epoch 5/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 584ms/step - accuracy: 0.7651 - loss: 0.8760 - val_accuracy: 0.7952 - val_loss: 0.7653\n",
      "Epoch 6/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 587ms/step - accuracy: 0.7715 - loss: 0.8466 - val_accuracy: 0.8072 - val_loss: 0.7253\n",
      "Epoch 7/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 592ms/step - accuracy: 0.7737 - loss: 0.8513 - val_accuracy: 0.8514 - val_loss: 0.6404\n",
      "Epoch 8/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 583ms/step - accuracy: 0.7942 - loss: 0.7968 - val_accuracy: 0.8193 - val_loss: 0.7498\n",
      "Epoch 9/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 581ms/step - accuracy: 0.8172 - loss: 0.7362 - val_accuracy: 0.8273 - val_loss: 0.6476\n",
      "Epoch 10/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 605ms/step - accuracy: 0.8025 - loss: 0.7421 - val_accuracy: 0.8474 - val_loss: 0.5856\n",
      "Epoch 11/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 610ms/step - accuracy: 0.8242 - loss: 0.7042 - val_accuracy: 0.8635 - val_loss: 0.5932\n",
      "Epoch 12/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 619ms/step - accuracy: 0.8018 - loss: 0.7614 - val_accuracy: 0.8353 - val_loss: 0.5915\n",
      "Epoch 13/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 617ms/step - accuracy: 0.8062 - loss: 0.7389 - val_accuracy: 0.8394 - val_loss: 0.6129\n",
      "Epoch 14/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 618ms/step - accuracy: 0.8075 - loss: 0.6810 - val_accuracy: 0.8514 - val_loss: 0.5488\n",
      "Epoch 15/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 631ms/step - accuracy: 0.8163 - loss: 0.6744 - val_accuracy: 0.8554 - val_loss: 0.5804\n",
      "Epoch 16/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 614ms/step - accuracy: 0.8295 - loss: 0.6551 - val_accuracy: 0.8434 - val_loss: 0.5879\n",
      "Epoch 17/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 630ms/step - accuracy: 0.8241 - loss: 0.6478 - val_accuracy: 0.8353 - val_loss: 0.6010\n",
      "Epoch 18/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 606ms/step - accuracy: 0.8469 - loss: 0.6391 - val_accuracy: 0.8514 - val_loss: 0.5364\n",
      "Epoch 19/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 586ms/step - accuracy: 0.8281 - loss: 0.6515 - val_accuracy: 0.8474 - val_loss: 0.6321\n",
      "Epoch 20/20\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 590ms/step - accuracy: 0.8578 - loss: 0.6141 - val_accuracy: 0.8675 - val_loss: 0.5615\n",
      "Epoch 1/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 858ms/step - accuracy: 0.7323 - loss: 0.9218 - val_accuracy: 0.8715 - val_loss: 0.5582\n",
      "Epoch 2/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 841ms/step - accuracy: 0.7754 - loss: 0.8062 - val_accuracy: 0.8554 - val_loss: 0.5297\n",
      "Epoch 3/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 841ms/step - accuracy: 0.7742 - loss: 0.7892 - val_accuracy: 0.9036 - val_loss: 0.4919\n",
      "Epoch 4/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 862ms/step - accuracy: 0.7914 - loss: 0.7498 - val_accuracy: 0.8594 - val_loss: 0.5635\n",
      "Epoch 5/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 866ms/step - accuracy: 0.7985 - loss: 0.7180 - val_accuracy: 0.8635 - val_loss: 0.5722\n",
      "Epoch 6/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 840ms/step - accuracy: 0.8049 - loss: 0.7193 - val_accuracy: 0.8715 - val_loss: 0.5714\n",
      "Epoch 7/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 839ms/step - accuracy: 0.8318 - loss: 0.6870 - val_accuracy: 0.8594 - val_loss: 0.5917\n",
      "Epoch 8/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 839ms/step - accuracy: 0.8158 - loss: 0.6836 - val_accuracy: 0.8675 - val_loss: 0.5288\n",
      "Epoch 9/10\n",
      "\u001b[1m49/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12s\u001b[0m 829ms/step - accuracy: 0.8204 - loss: 0.6668"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 数据加载\n",
    "batch_size = 32\n",
    "img_size = (224, 224)\n",
    "\n",
    "dataset_path = \"../dataset/Garbage classification/Garbage classification\"\n",
    "\n",
    "# 划分数据集（训练集80%，验证集10%，测试集10%）\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# 额外划分测试集（从验证集中拆分 50%）\n",
    "val_batches = len(val_dataset)\n",
    "test_size = val_batches // 2\n",
    "test_dataset = val_dataset.take(test_size)\n",
    "val_dataset = val_dataset.skip(test_size)\n",
    "\n",
    "# 打印类别索引映射\n",
    "class_names = train_dataset.class_names\n",
    "print(f\"类别索引映射: {class_names}\")\n",
    "\n",
    "# 统计训练数据中每个类别的样本数量\n",
    "class_counts = Counter()\n",
    "for images, labels in train_dataset:\n",
    "    class_counts.update(labels.numpy())\n",
    "\n",
    "# 打印类别分布\n",
    "for class_idx, count in class_counts.items():\n",
    "    print(f\"Class {class_names[class_idx]}: {count} samples\")\n",
    "\n",
    "# 数据增强\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.3),\n",
    "    layers.RandomZoom(0.3),\n",
    "    layers.RandomContrast(0.3),\n",
    "    layers.RandomBrightness(0.2),\n",
    "])\n",
    "\n",
    "# 加载预训练模型\n",
    "base_model = keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base_model.trainable = False  # 冻结特征提取层\n",
    "\n",
    "# 构建分类模型\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(6, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 训练模型（第一阶段）\n",
    "epochs = 20\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs=epochs)\n",
    "\n",
    "# 解冻更多层，进行微调（解冻 MobileNetV2 的后 50 层）\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:100]:  # 仅解冻后半部分层\n",
    "    layer.trainable = False\n",
    "\n",
    "# 重新编译模型\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 训练模型（微调阶段）\n",
    "fine_tune_epochs = 10\n",
    "history_fine = model.fit(train_dataset, validation_data=val_dataset, epochs=fine_tune_epochs)\n",
    "\n",
    "# 绘制训练曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'] + history_fine.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'] + history_fine.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'] + history_fine.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'] + history_fine.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 测试集评估\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"测试集准确率: {test_acc:.4f}\")\n",
    "\n",
    "# 获取真实标签和预测标签\n",
    "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "y_pred = np.argmax(model.predict(test_dataset), axis=1)\n",
    "\n",
    "# 生成完整分类报告（包含 F1-score、Recall、Precision）\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "print(report)\n",
    "\n",
    "# 保存模型\n",
    "model.save(\"classification_model.keras\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
